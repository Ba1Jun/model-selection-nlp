{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffa098d5-39d1-4ae6-830d-7e3591636a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca201c43-a8cb-4bfe-9b08-3fa44e38b6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([1, 2, 3, 4, 5])\n",
    "y[np.where(y==1)[0]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be724c56-8fb4-4e6b-b23a-03e80169a73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "320423e9-60a6-4f21-8cdd-6478dda2bfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191.49718165397644"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(time.time() - st_time) / 2 + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a152ca-e003-4188-aa4f-3fffc84b26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.binomial(1, 0.5, 2000)\n",
    "lsm = (y[:, None] == y[None, :]).astype(np.float32) * 2 - 1 # label similariy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d2d6934-88c0-4443-a899-9788b195dc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lsm * lsm) / (np.linalg.norm(lsm, ord=2) * np.linalg.norm(lsm, ord=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad4f616-919e-4db8-ac75-25aa853aa002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d81cf3-a8a4-4576-a368-c5fc74f15de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b9cc0b-d5da-4274-9189-9812f6edc434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39de19-9ecc-41b3-89f3-ac3bf0d3ea47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee2bcb-85c9-4322-847f-338708d85fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "076f5c8e-8ef9-4d22-909b-99413adb8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import weightedtau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0073083c-e681-4222-bbd3-5bf6c2420346",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dict = {\n",
    "    # Classification\n",
    "    \"agnews\": {\n",
    "        \"mean\": {\n",
    "            \"frozen\": [92.62, 93.30, 92.26, 87.52, 90.05, 92.55, 90.06],\n",
    "            \"tuned\": [93.51, 91.70, 93.85, 92.62, 93.16, 93.34, 92.40]\n",
    "        },\n",
    "        \"first\": {\n",
    "            \"frozen\": [91.52, 92.71, 91.65, 84.50, 88.84, 93.16, 89.25],\n",
    "            \"tuned\": [93.51, 92.57, 93.77, 93.05, 93.19, 93.15, 92.32]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"arline\": {\n",
    "        \"mean\": {\n",
    "            \"frozen\": [82.58, 84.10, 81.71, 78.46, 76.67, 84.89, 77.58],\n",
    "            \"tuned\": [84.03, 85.43, 83.89, 83.17, 82.55, 86.05, 82.05]\n",
    "        },\n",
    "        \"first\": {\n",
    "            \"frozen\": [80.88, 83.29, 79.95, 75.98, 75.50, 84.57, 76.01],\n",
    "            \"tuned\": [84.27, 85.19, 83.99, 82.70, 81.62, 85.51, 82.27]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"scierc\": {\n",
    "        \"mean\": {\n",
    "            \"frozen\": [49.56, 51.07, 45.98, 48.64, 56.64, 46.75, 58.83],\n",
    "            \"tuned\": [75.84, 78.80, 73.13, 73.61, 81.60, 76.65, 80.12]\n",
    "        },\n",
    "        \"first\": {\n",
    "            \"frozen\": [41.94, 40.51, 41.35, 42.94, 41.98, 42.87, 45.35],\n",
    "            \"tuned\": [80.20, 67.71, 75.95, 76.57, 83.89, 78.25, 82.93]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"mnli\": {\n",
    "        \"mean\": {\n",
    "            \"frozen\": [59.18, 64.18, 58.13, 56.53, 60.12, 61.77, 59.57],\n",
    "            \"tuned\": [81.85, 86.57, 79.64, 79.21, 80.89, 85.41, 80.41]\n",
    "        },\n",
    "        \"first\": {\n",
    "            \"frozen\": [59.64, 61.48, 57.13, 57.52, 62.40, 59.23, 61.59],\n",
    "            \"tuned\": [82.23, 86.71, 80.54, 79.54, 80.84, 85.32, 80.40]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"qnli\": {\n",
    "        \"mean\": {\n",
    "            \"frozen\": [75.75, 78.09, 74.25, 74.69, 78.21, 77.49, 76.84],\n",
    "            \"tuned\": [88.17, 92.17, 86.26, 84.13, 88.19, 91.22, 87.24]\n",
    "        },\n",
    "        \"first\": {\n",
    "            \"frozen\": [72.23, 74.42, 71.55, 73.67, 77.25, 73.99, 76.31],\n",
    "            \"tuned\": [88.46, 92.23, 86.68, 84.31, 88.57, 91.03, 86.77]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"rte\": {\n",
    "        \"mean\": {\n",
    "            \"frozen\": [56.26, 58.35, 53.96, 58.13, 56.97, 54.02, 55.46],\n",
    "            \"tuned\": [62.09, 68.99, 57.63, 58.99, 59.98, 66.63, 64.65]\n",
    "        },\n",
    "        \"first\": {\n",
    "            \"frozen\": [58.56, 56.04, 55.40, 55.46, 58.05, 54.10, 59.64],\n",
    "            \"tuned\": [60.14, 67.05, 60.07, 57.64, 63.12, 63.21, 64.83]\n",
    "        }\n",
    "    },\n",
    "    # Structured Prediction\n",
    "    \"en-ewt\": {\n",
    "        \"mean\": {\n",
    "            \"frozen\": [85.04, 86.10, 86.98, 85.05, 85.95, 86.50, 87.54],\n",
    "            \"tuned\": [94.16, 94.85, 93.36, 93.10, 93.16, 94.82, 93.29]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"crossner-news\": {\n",
    "        \"mean\": {\n",
    "            \"frozen\": [87.66, 88.08, 88.41, 69.86, 81.48, 88.55, 82.38],\n",
    "            \"tuned\": [92.53, 94.59, 91.21, 78.01, 89.63, 94.23, 88.16]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"crossner-sci\": {\n",
    "        \"mean\": {\n",
    "            \"frozen\": [43.22, 47.00, 45.96, 32.89, 43.24, 45.51, 43.98],\n",
    "            \"tuned\": [38.68, 62.27, 37.97, 20.96, 47.73, 54.05, 53.44]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"jobstack\": {\n",
    "        \"mean\": {\n",
    "            \"frozen\": [73.64, 74.06, 74.96, 61.13, 68.32, 73.72, 71.66],\n",
    "            \"tuned\": [78.49, 81.51, 77.02, 67.07, 74.65, 79.99, 78.72]\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af27eb-b1d6-4ec2-9997-0a64cd873981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cdaffc-b8d6-4d5d-8cc6-08b3706eaaff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d26325e-460d-4236-80d9-fb67654782c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45621da6-2aff-451f-b023-ec54a997ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earlystop_result(dataset, pooling, epochs, train_type):\n",
    "    seeds = [4012, 5060, 8823, 8857, 9908]\n",
    "    method_result_list = [0., 0., 0., 0., 0., 0., 0.]\n",
    "    method_result_folder = f'../../resources/output/{dataset}/earlystopping-{epochs}/{train_type}'\n",
    "    for i in range(7):\n",
    "        for seed in seeds:\n",
    "            result_json = method_result_folder + f'/model{i}-{pooling}-mlp-rs{seed}/{dataset}-validation-pred-results.json'\n",
    "            with open(result_json, \"r\", encoding=\"utf-8\") as f:\n",
    "                result = json.load(f)\n",
    "                method_result_list[i] += result['micro-F1']\n",
    "        method_result_list[i] /= 5\n",
    "        method_result_list[i] = round(method_result_list[i], 2)\n",
    "    return method_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1517e02-596a-4222-8e43-31cf09d22947",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['rte']\n",
    "encoders = [\"bert-base-uncased\",\n",
    "            \"roberta-base\",\n",
    "            \"distilbert-base-uncased\",\n",
    "            \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "            \"dmis-lab/biobert-v1.1\",\n",
    "            \"cardiffnlp/twitter-roberta-base\",\n",
    "            \"allenai/scibert_scivocab_uncased\"]\n",
    "\n",
    "all_dt_results = {}\n",
    "all_methods = ['EarlyStop-1', 'EarlyStop-3', 'kNN', 'Logistic', 'MSC', 'LFC', 'HScore', 'HScoreR', 'LogME', 'GBC', 'PARC', 'SFDA', 'TransRate', 'NLEEP']\n",
    "for dataset in datasets:\n",
    "    if not os.path.exists(f'../../resources/output/{dataset}/'):\n",
    "        continue\n",
    "    # all_methods = set([file.split('_')[0] for file in os.listdir(f'../../resources/output/{dataset}/results/')])\n",
    "    for pooling in ['first']:\n",
    "        dt_results = {\n",
    "            \"Language Model\": encoders,\n",
    "            \"Frozen\": gt_dict[dataset][pooling][\"frozen\"],\n",
    "            \"Tuned\": gt_dict[dataset][pooling][\"tuned\"]\n",
    "        }\n",
    "        for method in all_methods:\n",
    "            \n",
    "            if method == 'EarlyStop-1':\n",
    "                method_result_list = get_earlystop_result(dataset, pooling, 1, 'frozen')\n",
    "            elif method == 'EarlyStop-3':\n",
    "                method_result_list = get_earlystop_result(dataset, pooling, 3, 'frozen')\n",
    "            else:\n",
    "                method_result_file = f'../../resources/output/{dataset}/results/{method}_{pooling}.txt'\n",
    "                with open(method_result_file, 'r', encoding='utf-8') as f:\n",
    "                    method_result_lines = f.readlines()\n",
    "                method_result_list = []\n",
    "                for line in method_result_lines:\n",
    "                    score = line.strip().split(' ')[-1]\n",
    "                    method_result_list.append(float(score))\n",
    "            dt_results[method] = method_result_list\n",
    "        \n",
    "        all_dt_results[f\"{dataset}-{pooling}\"] = pd.DataFrame(dt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01c8d399-0b47-4e8d-8cfa-a0eadd2d8faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rte-first'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dt_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7788c1b-ebfe-4cb5-b40d-5db086590c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language Model</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Tuned</th>\n",
       "      <th>EarlyStop-1</th>\n",
       "      <th>EarlyStop-3</th>\n",
       "      <th>kNN</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>MSC</th>\n",
       "      <th>LFC</th>\n",
       "      <th>HScore</th>\n",
       "      <th>HScoreR</th>\n",
       "      <th>LogME</th>\n",
       "      <th>GBC</th>\n",
       "      <th>PARC</th>\n",
       "      <th>SFDA</th>\n",
       "      <th>TransRate</th>\n",
       "      <th>NLEEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>58.56</td>\n",
       "      <td>60.14</td>\n",
       "      <td>50.36</td>\n",
       "      <td>57.84</td>\n",
       "      <td>0.5054</td>\n",
       "      <td>0.5199</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>-0.7176</td>\n",
       "      <td>-1.3267</td>\n",
       "      <td>0.4695</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>94.0101</td>\n",
       "      <td>0.5040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>56.04</td>\n",
       "      <td>67.05</td>\n",
       "      <td>49.64</td>\n",
       "      <td>54.24</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.4516</td>\n",
       "      <td>0.3465</td>\n",
       "      <td>-0.7015</td>\n",
       "      <td>-1.2817</td>\n",
       "      <td>0.5921</td>\n",
       "      <td>0.5545</td>\n",
       "      <td>15.7446</td>\n",
       "      <td>0.5049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>55.40</td>\n",
       "      <td>60.07</td>\n",
       "      <td>50.36</td>\n",
       "      <td>55.40</td>\n",
       "      <td>0.4874</td>\n",
       "      <td>0.5235</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>-0.7251</td>\n",
       "      <td>-1.5517</td>\n",
       "      <td>0.1639</td>\n",
       "      <td>0.5567</td>\n",
       "      <td>81.5544</td>\n",
       "      <td>0.5016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emilyalsentzer/Bio_ClinicalBERT</td>\n",
       "      <td>55.46</td>\n",
       "      <td>57.64</td>\n",
       "      <td>50.79</td>\n",
       "      <td>53.81</td>\n",
       "      <td>0.4946</td>\n",
       "      <td>0.5379</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>-0.7188</td>\n",
       "      <td>-1.3086</td>\n",
       "      <td>0.3683</td>\n",
       "      <td>0.5546</td>\n",
       "      <td>82.3709</td>\n",
       "      <td>0.5023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dmis-lab/biobert-v1.1</td>\n",
       "      <td>58.05</td>\n",
       "      <td>63.12</td>\n",
       "      <td>53.81</td>\n",
       "      <td>58.92</td>\n",
       "      <td>0.5451</td>\n",
       "      <td>0.6173</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.4052</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>-0.7118</td>\n",
       "      <td>-1.3179</td>\n",
       "      <td>0.4398</td>\n",
       "      <td>0.5659</td>\n",
       "      <td>78.5851</td>\n",
       "      <td>0.5022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardiffnlp/twitter-roberta-base</td>\n",
       "      <td>54.10</td>\n",
       "      <td>63.21</td>\n",
       "      <td>49.93</td>\n",
       "      <td>54.24</td>\n",
       "      <td>0.5090</td>\n",
       "      <td>0.4982</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3808</td>\n",
       "      <td>0.2812</td>\n",
       "      <td>-0.7197</td>\n",
       "      <td>-1.4424</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.5334</td>\n",
       "      <td>21.1391</td>\n",
       "      <td>0.5057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>allenai/scibert_scivocab_uncased</td>\n",
       "      <td>59.64</td>\n",
       "      <td>64.83</td>\n",
       "      <td>55.04</td>\n",
       "      <td>55.97</td>\n",
       "      <td>0.5199</td>\n",
       "      <td>0.5560</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.4044</td>\n",
       "      <td>0.3463</td>\n",
       "      <td>-0.7149</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>0.4004</td>\n",
       "      <td>0.5663</td>\n",
       "      <td>94.0239</td>\n",
       "      <td>0.5056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Language Model  Frozen  Tuned  EarlyStop-1  EarlyStop-3   \n",
       "0                 bert-base-uncased   58.56  60.14        50.36        57.84  \\\n",
       "1                      roberta-base   56.04  67.05        49.64        54.24   \n",
       "2           distilbert-base-uncased   55.40  60.07        50.36        55.40   \n",
       "3   emilyalsentzer/Bio_ClinicalBERT   55.46  57.64        50.79        53.81   \n",
       "4             dmis-lab/biobert-v1.1   58.05  63.12        53.81        58.92   \n",
       "5   cardiffnlp/twitter-roberta-base   54.10  63.21        49.93        54.24   \n",
       "6  allenai/scibert_scivocab_uncased   59.64  64.83        55.04        55.97   \n",
       "\n",
       "      kNN  Logistic     MSC     LFC  HScore  HScoreR   LogME     GBC    PARC   \n",
       "0  0.5054    0.5199  0.0013  0.0075  0.4020   0.3429 -0.7176 -1.3267  0.4695  \\\n",
       "1  0.4910    0.5848  0.0014  0.0005  0.4516   0.3465 -0.7015 -1.2817  0.5921   \n",
       "2  0.4874    0.5235  0.0005  0.0028  0.3700   0.2991 -0.7251 -1.5517  0.1639   \n",
       "3  0.4946    0.5379  0.0014  0.0062  0.3495   0.3140 -0.7188 -1.3086  0.3683   \n",
       "4  0.5451    0.6173  0.0014  0.0052  0.4052   0.3525 -0.7118 -1.3179  0.4398   \n",
       "5  0.5090    0.4982  0.0009  0.0005  0.3808   0.2812 -0.7197 -1.4424  0.2884   \n",
       "6  0.5199    0.5560  0.0013  0.0066  0.4044   0.3463 -0.7149 -1.3222  0.4004   \n",
       "\n",
       "     SFDA  TransRate   NLEEP  \n",
       "0  0.5629    94.0101  0.5040  \n",
       "1  0.5545    15.7446  0.5049  \n",
       "2  0.5567    81.5544  0.5016  \n",
       "3  0.5546    82.3709  0.5023  \n",
       "4  0.5659    78.5851  0.5022  \n",
       "5  0.5334    21.1391  0.5057  \n",
       "6  0.5663    94.0239  0.5056  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dt_results['rte-first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b1da5-fede-4dae-bf68-81ad77733f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63420b44-97c3-4425-ad96-f4ba80c8423a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e0ae6b5-b20b-44f7-b860-f95e3825c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(gt_dict.keys())\n",
    "encoders = [\"bert-base-uncased\",\n",
    "            \"roberta-base\",\n",
    "            \"distilbert-base-uncased\",\n",
    "            \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "            \"dmis-lab/biobert-v1.1\",\n",
    "            \"cardiffnlp/twitter-roberta-base\",\n",
    "            \"allenai/scibert_scivocab_uncased\"]\n",
    "\n",
    "all_corr_results = {}\n",
    "\n",
    "all_methods = ['EarlyStop-1', 'EarlyStop-3', 'kNN', 'Logistic', 'MSC', 'LFC', 'HScore', 'HScoreR', 'LogME', 'GBC', 'PARC', 'SFDA', 'TransRate', 'NLEEP']\n",
    "\n",
    "for pooling in ['first']:\n",
    "    for train_type in ['frozen', 'tuned']:\n",
    "        corr_results = {\n",
    "            \"Methods\": all_methods\n",
    "        }\n",
    "        \n",
    "        for dataset in datasets:\n",
    "            if not os.path.exists(f'../../resources/output/{dataset}/'):\n",
    "                continue\n",
    "            corr_results[dataset+'-rho'] = []\n",
    "            corr_results[dataset+'-tau'] = []\n",
    "            for method in all_methods:\n",
    "                if method == 'EarlyStop-1':\n",
    "                    method_result_list = get_earlystop_result(dataset, pooling, 1, 'frozen')\n",
    "                elif method == 'EarlyStop-3':\n",
    "                    method_result_list = get_earlystop_result(dataset, pooling, 3, 'frozen')\n",
    "                else:   \n",
    "                    method_result_file = f'../../resources/output/{dataset}/results/{method}_{pooling}.txt'\n",
    "                    with open(method_result_file, 'r', encoding='utf-8') as f:\n",
    "                        method_result_lines = f.readlines()\n",
    "                    method_result_list = []\n",
    "                    for line in method_result_lines:\n",
    "                        score = line.strip().split(' ')[-1]\n",
    "                        method_result_list.append(float(score))\n",
    "\n",
    "                rho = pearsonr(method_result_list, gt_dict[dataset][pooling][train_type]).statistic\n",
    "                tau = weightedtau(method_result_list, gt_dict[dataset][pooling][train_type]).statistic\n",
    "                corr_results[dataset+'-rho'].append(round(rho, 3))\n",
    "                corr_results[dataset+'-tau'].append(round(tau, 3))\n",
    "        all_corr_results[f\"{train_type}-{pooling}\"] = pd.DataFrame(corr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8758c2d4-c981-4630-af65-dc31f3a4a2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['frozen-first', 'tuned-first'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_corr_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "037e5a2f-28b3-4f63-9b0f-1fde657afa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>rte-rho</th>\n",
       "      <th>rte-tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EarlyStop-1</td>\n",
       "      <td>0.218</td>\n",
       "      <td>-0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EarlyStop-3</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSC</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LFC</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>-0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HScore</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HScoreR</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogME</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PARC</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SFDA</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TransRate</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>-0.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NLEEP</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Methods  rte-rho  rte-tau\n",
       "0   EarlyStop-1    0.218   -0.101\n",
       "1   EarlyStop-3   -0.002   -0.053\n",
       "2           kNN    0.245    0.077\n",
       "3      Logistic    0.465    0.269\n",
       "4           MSC    0.227    0.313\n",
       "5           LFC   -0.488   -0.319\n",
       "6        HScore    0.864    0.753\n",
       "7       HScoreR    0.388    0.371\n",
       "8         LogME    0.754    0.661\n",
       "9           GBC    0.291    0.417\n",
       "10         PARC    0.521    0.496\n",
       "11         SFDA   -0.016    0.144\n",
       "12    TransRate   -0.571   -0.207\n",
       "13        NLEEP    0.654    0.382"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_corr_results['tuned-first']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
